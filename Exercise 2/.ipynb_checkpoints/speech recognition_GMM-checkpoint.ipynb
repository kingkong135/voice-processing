{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentiendat/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sequence\n",
      "/home/nguyentiendat/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:18: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Iterable\n",
      "/home/nguyentiendat/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:16: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, namedtuple, defaultdict, Sequence\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path) # read .wav file\n",
    "    hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "    win_length = math.floor(sr*0.025) # 25ms frame\n",
    "    # mfcc is 12 x T matrix\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y, sr, n_mfcc=12, n_fft=1024,\n",
    "        hop_length=hop_length, win_length=win_length)\n",
    "    # substract mean from mfcc --> normalize mfcc\n",
    "    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "    # delta feature 1st order and 2nd order\n",
    "    delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    # X is 36 x T\n",
    "    X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "    # return T x 36 (transpose of X)\n",
    "    return X.T # hmmlearn use T x N matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_data(data_dir):\n",
    "    files = os.listdir(data_dir)\n",
    "    mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(X, n_clusters=10):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0, verbose=0)\n",
    "    kmeans.fit(X)\n",
    "    print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "    return kmeans  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load toi dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentiendat/anaconda3/lib/python3.7/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load trong dataset\n",
      "Load truoc dataset\n",
      "Load nhan_vien dataset\n",
      "Load gia_dinh dataset\n",
      "Load test_toi dataset\n",
      "Load test_trong dataset\n",
      "Load test_truoc dataset\n",
      "Load test_nhan_vien dataset\n",
      "Load test_gia_dinh dataset\n",
      "vectors (19071, 36)\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"toi\", \"trong\", \"truoc\", \"nhan_vien\", \"gia_dinh\", \"test_toi\", \"test_trong\", \"test_truoc\", \n",
    "               \"test_nhan_vien\", \"test_gia_dinh\"]\n",
    "dataset = {}\n",
    "for cname in class_names:\n",
    "    print(f\"Load {cname} dataset\")\n",
    "    dataset[cname] = get_class_data(os.path.join(\"data\", cname))\n",
    "\n",
    "# Get all vectors in the datasets\n",
    "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
    "print(\"vectors\", all_vectors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class toi\n",
      "(2269, 36) [22, 36, 28, 39, 33, 23, 23, 21, 23, 40, 48, 12, 36, 18, 25, 12, 22, 14, 23, 34, 22, 10, 84, 47, 22, 29, 25, 30, 17, 19, 31, 24, 27, 19, 38, 25, 21, 84, 24, 17, 17, 17, 16, 36, 17, 18, 18, 32, 33, 18, 47, 19, 18, 24, 33, 16, 23, 31, 37, 17, 49, 31, 30, 24, 82, 17, 16, 57, 24, 31, 16, 20, 20, 20, 49, 31, 34, 23, 22, 39] 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -232562.0841             +nan\n",
      "         2     -222998.6040       +9563.4801\n",
      "         3     -220121.8832       +2876.7209\n",
      "         4     -219577.2944        +544.5888\n",
      "         5     -219428.2236        +149.0708\n",
      "         6     -219306.3538        +121.8698\n",
      "         7     -219224.4838         +81.8700\n",
      "         8     -219154.2286         +70.2552\n",
      "         9     -219098.1586         +56.0700\n",
      "        10     -219052.8686         +45.2900\n",
      "        11     -218979.6957         +73.1730\n",
      "        12     -218867.3381        +112.3576\n",
      "        13     -218751.8447        +115.4934\n",
      "        14     -218640.7991        +111.0456\n",
      "        15     -218521.2808        +119.5183\n",
      "        16     -218406.7541        +114.5267\n",
      "        17     -218332.1784         +74.5757\n",
      "        18     -218284.2009         +47.9775\n",
      "        19     -218243.5839         +40.6170\n",
      "        20     -218224.2483         +19.3356\n",
      "        21     -218214.1062         +10.1422\n",
      "        22     -218208.8604          +5.2458\n",
      "        23     -218203.3024          +5.5580\n",
      "        24     -218196.8992          +6.4032\n",
      "        25     -218188.7877          +8.1115\n",
      "        26     -218173.8292         +14.9584\n",
      "        27     -218155.4928         +18.3364\n",
      "        28     -218135.2018         +20.2910\n",
      "        29     -218118.3784         +16.8234\n",
      "        30     -218103.8085         +14.5699\n",
      "        31     -218088.7773         +15.0312\n",
      "        32     -218076.0161         +12.7611\n",
      "        33     -218061.7854         +14.2308\n",
      "        34     -218053.7360          +8.0494\n",
      "        35     -218049.2116          +4.5244\n",
      "        36     -218045.0617          +4.1498\n",
      "        37     -218038.8491          +6.2126\n",
      "        38     -218030.9726          +7.8766\n",
      "        39     -218015.0816         +15.8909\n",
      "        40     -217993.7682         +21.3134\n",
      "        41     -217954.9927         +38.7755\n",
      "        42     -217913.5264         +41.4663\n",
      "        43     -217874.5854         +38.9410\n",
      "        44     -217811.6225         +62.9629\n",
      "        45     -217768.5795         +43.0430\n",
      "        46     -217743.6398         +24.9396\n",
      "        47     -217719.1066         +24.5332\n",
      "        48     -217713.7357          +5.3709\n",
      "        49     -217707.0608          +6.6749\n",
      "        50     -217703.8716          +3.1892\n",
      "        51     -217702.6938          +1.1778\n",
      "        52     -217701.6786          +1.0152\n",
      "        53     -217700.1199          +1.5588\n",
      "        54     -217692.4759          +7.6440\n",
      "        55     -217687.9170          +4.5589\n",
      "        56     -217686.0694          +1.8476\n",
      "        57     -217682.8878          +3.1816\n",
      "        58     -217678.2512          +4.6366\n",
      "        59     -217671.6426          +6.6086\n",
      "        60     -217666.7998          +4.8429\n",
      "        61     -217666.0002          +0.7996\n",
      "        62     -217665.5782          +0.4220\n",
      "        63     -217665.2800          +0.2982\n",
      "        64     -217665.0166          +0.2633\n",
      "        65     -217664.7067          +0.3099\n",
      "        66     -217664.2621          +0.4446\n",
      "        67     -217663.6224          +0.6397\n",
      "        68     -217662.7846          +0.8379\n",
      "        69     -217661.9918          +0.7928\n",
      "        70     -217661.5615          +0.4303\n",
      "        71     -217661.3714          +0.1901\n",
      "        72     -217661.2675          +0.1038\n",
      "        73     -217661.1972          +0.0704\n",
      "        74     -217661.1417          +0.0555\n",
      "        75     -217661.0923          +0.0493\n",
      "        76     -217661.0435          +0.0488\n",
      "        77     -217660.9897          +0.0538\n",
      "        78     -217660.9235          +0.0663\n",
      "        79     -217660.8335          +0.0900\n",
      "        80     -217660.7040          +0.1295\n",
      "        81     -217660.5215          +0.1826\n",
      "        82     -217660.2936          +0.2279\n",
      "        83     -217660.0554          +0.2383\n",
      "        84     -217659.8350          +0.2204\n",
      "        85     -217659.6382          +0.1967\n",
      "        86     -217659.4630          +0.1753\n",
      "        87     -217659.3069          +0.1561\n",
      "        88     -217659.1687          +0.1382\n",
      "        89     -217659.0477          +0.1210\n",
      "        90     -217658.9429          +0.1048\n",
      "        91     -217658.8525          +0.0904\n",
      "        92     -217658.7740          +0.0785\n",
      "        93     -217658.7048          +0.0692\n",
      "        94     -217658.6422          +0.0626\n",
      "        95     -217658.5836          +0.0586\n",
      "        96     -217658.5259          +0.0577\n",
      "        97     -217658.4654          +0.0605\n",
      "        98     -217658.3967          +0.0686\n",
      "        99     -217658.3135          +0.0833\n",
      "       100     -217658.2106          +0.1029\n",
      "       101     -217658.0908          +0.1198\n",
      "       102     -217657.9661          +0.1247\n",
      "       103     -217657.8465          +0.1196\n",
      "       104     -217657.7352          +0.1113\n",
      "       105     -217657.6369          +0.0984\n",
      "       106     -217657.5586          +0.0783\n",
      "       107     -217657.5030          +0.0556\n",
      "       108     -217657.4666          +0.0364\n",
      "       109     -217657.4434          +0.0231\n",
      "       110     -217657.4287          +0.0147\n",
      "       111     -217657.4191          +0.0095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class trong\n",
      "(3738, 36) [20, 32, 22, 17, 25, 26, 22, 18, 21, 22, 16, 19, 21, 19, 25, 21, 20, 26, 24, 31, 21, 32, 19, 18, 23, 21, 20, 25, 22, 19, 15, 31, 24, 19, 24, 22, 28, 23, 20, 25, 22, 19, 18, 26, 20, 16, 18, 23, 19, 21, 31, 21, 21, 26, 32, 29, 21, 20, 18, 33, 20, 23, 19, 26, 25, 18, 15, 27, 13, 17, 26, 22, 23, 25, 24, 25, 18, 32, 18, 18, 25, 18, 20, 16, 18, 20, 19, 19, 23, 35, 19, 25, 20, 19, 25, 18, 23, 17, 28, 27, 21, 20, 17, 22, 20, 21, 16, 19, 28, 27, 23, 23, 23, 24, 19, 24, 21, 29, 24, 19, 20, 23, 19, 20, 22, 29, 22, 18, 23, 28, 15, 17, 23, 26, 17, 18, 16, 28, 29, 22, 22, 29, 25, 24, 24, 14, 23, 27, 14, 20, 19, 21, 21, 22, 26, 19, 21, 19, 27, 22, 26, 14, 25, 23, 25, 21, 26, 20, 24] 169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -388521.5609             +nan\n",
      "         2     -367039.3710      +21482.1899\n",
      "         3     -364600.7179       +2438.6531\n",
      "         4     -363766.2564        +834.4616\n",
      "         5     -363300.8230        +465.4333\n",
      "         6     -362977.7329        +323.0902\n",
      "         7     -362780.2835        +197.4493\n",
      "         8     -362589.6689        +190.6146\n",
      "         9     -362442.1641        +147.5048\n",
      "        10     -362320.4682        +121.6959\n",
      "        11     -362229.8159         +90.6524\n",
      "        12     -362147.1482         +82.6677\n",
      "        13     -362067.2437         +79.9045\n",
      "        14     -362002.7081         +64.5357\n",
      "        15     -361953.5489         +49.1592\n",
      "        16     -361916.3333         +37.2155\n",
      "        17     -361888.2785         +28.0549\n",
      "        18     -361856.7213         +31.5572\n",
      "        19     -361842.5403         +14.1810\n",
      "        20     -361830.9506         +11.5896\n",
      "        21     -361821.2370          +9.7137\n",
      "        22     -361812.4922          +8.7448\n",
      "        23     -361803.0965          +9.3956\n",
      "        24     -361793.0131         +10.0835\n",
      "        25     -361779.7852         +13.2279\n",
      "        26     -361768.1994         +11.5857\n",
      "        27     -361750.4749         +17.7246\n",
      "        28     -361729.9601         +20.5148\n",
      "        29     -361699.2186         +30.7415\n",
      "        30     -361684.5832         +14.6353\n",
      "        31     -361675.2777          +9.3055\n",
      "        32     -361665.6569          +9.6207\n",
      "        33     -361663.0458          +2.6112\n",
      "        34     -361661.3728          +1.6729\n",
      "        35     -361660.2463          +1.1265\n",
      "        36     -361659.4435          +0.8029\n",
      "        37     -361658.8241          +0.6193\n",
      "        38     -361658.2888          +0.5353\n",
      "        39     -361657.7609          +0.5279\n",
      "        40     -361657.1786          +0.5823\n",
      "        41     -361656.4801          +0.6985\n",
      "        42     -361655.5672          +0.9129\n",
      "        43     -361654.1601          +1.4072\n",
      "        44     -361651.3107          +2.8494\n",
      "        45     -361647.0990          +4.2117\n",
      "        46     -361642.3172          +4.7818\n",
      "        47     -361634.7351          +7.5821\n",
      "        48     -361619.6000         +15.1351\n",
      "        49     -361586.5788         +33.0211\n",
      "        50     -361524.6306         +61.9483\n",
      "        51     -361458.8960         +65.7346\n",
      "        52     -361421.7569         +37.1391\n",
      "        53     -361399.6714         +22.0855\n",
      "        54     -361389.0511         +10.6203\n",
      "        55     -361378.6304         +10.4207\n",
      "        56     -361359.9444         +18.6859\n",
      "        57     -361344.4376         +15.5068\n",
      "        58     -361336.9245          +7.5131\n",
      "        59     -361326.5346         +10.3899\n",
      "        60     -361312.7460         +13.7885\n",
      "        61     -361299.7735         +12.9725\n",
      "        62     -361295.6210          +4.1525\n",
      "        63     -361294.0304          +1.5906\n",
      "        64     -361293.1865          +0.8439\n",
      "        65     -361292.6790          +0.5075\n",
      "        66     -361292.3520          +0.3270\n",
      "        67     -361292.1302          +0.2218\n",
      "        68     -361291.9738          +0.1565\n",
      "        69     -361291.8600          +0.1137\n",
      "        70     -361291.7756          +0.0845\n",
      "        71     -361291.7118          +0.0638\n",
      "        72     -361291.6631          +0.0487\n",
      "        73     -361291.6257          +0.0375\n",
      "        74     -361291.5967          +0.0290\n",
      "        75     -361291.5742          +0.0225\n",
      "        76     -361291.5567          +0.0175\n",
      "        77     -361291.5432          +0.0135\n",
      "        78     -361291.5327          +0.0105\n",
      "        79     -361291.5246          +0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class truoc\n",
      "(2227, 36) [27, 20, 41, 31, 24, 26, 41, 21, 31, 26, 18, 23, 32, 23, 26, 21, 21, 37, 36, 26, 31, 15, 17, 19, 23, 41, 25, 31, 31, 26, 31, 26, 19, 35, 21, 22, 24, 20, 11, 31, 31, 22, 29, 33, 22, 29, 22, 23, 24, 31, 21, 31, 26, 25, 20, 27, 19, 28, 27, 36, 25, 35, 23, 31, 21, 41, 41, 36, 27, 61, 43, 43, 35, 36, 20, 19, 19, 46, 31, 18] 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -232564.0341             +nan\n",
      "         2     -218895.3149      +13668.7192\n",
      "         3     -216834.7499       +2060.5650\n",
      "         4     -216319.5405        +515.2095\n",
      "         5     -216002.1082        +317.4323\n",
      "         6     -215897.3326        +104.7756\n",
      "         7     -215830.7318         +66.6009\n",
      "         8     -215778.8870         +51.8447\n",
      "         9     -215741.6976         +37.1894\n",
      "        10     -215721.5032         +20.1944\n",
      "        11     -215704.6931         +16.8101\n",
      "        12     -215691.9961         +12.6970\n",
      "        13     -215682.2807          +9.7153\n",
      "        14     -215674.3626          +7.9181\n",
      "        15     -215664.5618          +9.8007\n",
      "        16     -215644.5111         +20.0507\n",
      "        17     -215630.2529         +14.2582\n",
      "        18     -215625.2536          +4.9993\n",
      "        19     -215621.6330          +3.6206\n",
      "        20     -215616.9316          +4.7014\n",
      "        21     -215607.7991          +9.1325\n",
      "        22     -215599.8450          +7.9542\n",
      "        23     -215593.9774          +5.8676\n",
      "        24     -215581.9922         +11.9851\n",
      "        25     -215567.3712         +14.6211\n",
      "        26     -215554.3928         +12.9783\n",
      "        27     -215539.8509         +14.5419\n",
      "        28     -215525.9782         +13.8727\n",
      "        29     -215513.5434         +12.4348\n",
      "        30     -215499.9691         +13.5742\n",
      "        31     -215483.2782         +16.6909\n",
      "        32     -215467.6775         +15.6007\n",
      "        33     -215456.9937         +10.6838\n",
      "        34     -215449.7916          +7.2021\n",
      "        35     -215436.8720         +12.9195\n",
      "        36     -215426.9936          +9.8785\n",
      "        37     -215424.8599          +2.1337\n",
      "        38     -215423.7429          +1.1170\n",
      "        39     -215422.8958          +0.8471\n",
      "        40     -215422.0264          +0.8694\n",
      "        41     -215420.7313          +1.2951\n",
      "        42     -215418.9515          +1.7798\n",
      "        43     -215417.6701          +1.2814\n",
      "        44     -215417.1165          +0.5536\n",
      "        45     -215416.7991          +0.3174\n",
      "        46     -215416.5179          +0.2811\n",
      "        47     -215416.1640          +0.3539\n",
      "        48     -215415.5553          +0.6087\n",
      "        49     -215414.3154          +1.2399\n",
      "        50     -215411.8478          +2.4676\n",
      "        51     -215408.0610          +3.7868\n",
      "        52     -215403.4787          +4.5824\n",
      "        53     -215398.7077          +4.7710\n",
      "        54     -215395.4508          +3.2569\n",
      "        55     -215392.7498          +2.7010\n",
      "        56     -215390.5475          +2.2023\n",
      "        57     -215388.8080          +1.7395\n",
      "        58     -215387.1567          +1.6512\n",
      "        59     -215385.5520          +1.6048\n",
      "        60     -215384.0227          +1.5292\n",
      "        61     -215382.5862          +1.4365\n",
      "        62     -215381.6949          +0.8913\n",
      "        63     -215381.2010          +0.4939\n",
      "        64     -215380.8428          +0.3581\n",
      "        65     -215380.5916          +0.2513\n",
      "        66     -215380.4302          +0.1614\n",
      "        67     -215380.3376          +0.0926\n",
      "        68     -215380.2881          +0.0494\n",
      "        69     -215380.2619          +0.0262\n",
      "        70     -215380.2475          +0.0144\n",
      "        71     -215380.2393          +0.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class nhan_vien\n",
      "(3680, 36) [50, 53, 65, 29, 33, 53, 50, 55, 31, 44, 40, 42, 36, 42, 46, 32, 40, 55, 39, 42, 37, 38, 36, 29, 55, 38, 68, 57, 33, 55, 55, 43, 53, 48, 55, 48, 53, 49, 62, 40, 49, 50, 41, 42, 53, 55, 30, 38, 78, 52, 56, 40, 38, 35, 44, 50, 38, 41, 36, 34, 63, 54, 65, 29, 36, 34, 35, 63, 44, 45, 38, 40, 43, 43, 33, 36, 39, 44, 38, 43, 32, 54] 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -362015.3092             +nan\n",
      "         2     -349280.5081      +12734.8011\n",
      "         3     -345943.0340       +3337.4741\n",
      "         4     -345001.2736        +941.7604\n",
      "         5     -344484.4767        +516.7970\n",
      "         6     -344207.6127        +276.8640\n",
      "         7     -344000.8928        +206.7199\n",
      "         8     -343840.3241        +160.5688\n",
      "         9     -343701.1821        +139.1419\n",
      "        10     -343573.0440        +128.1381\n",
      "        11     -343457.8060        +115.2380\n",
      "        12     -343361.8628         +95.9432\n",
      "        13     -343274.9248         +86.9379\n",
      "        14     -343214.2010         +60.7239\n",
      "        15     -343163.3987         +50.8022\n",
      "        16     -343124.1137         +39.2850\n",
      "        17     -343094.1701         +29.9436\n",
      "        18     -343065.3256         +28.8445\n",
      "        19     -343033.1084         +32.2172\n",
      "        20     -343001.3083         +31.8001\n",
      "        21     -342969.3527         +31.9556\n",
      "        22     -342944.0768         +25.2759\n",
      "        23     -342927.6231         +16.4537\n",
      "        24     -342913.4854         +14.1377\n",
      "        25     -342899.6395         +13.8459\n",
      "        26     -342886.4919         +13.1476\n",
      "        27     -342874.8140         +11.6779\n",
      "        28     -342865.0844          +9.7296\n",
      "        29     -342856.8008          +8.2836\n",
      "        30     -342848.9756          +7.8252\n",
      "        31     -342836.6917         +12.2839\n",
      "        32     -342801.0709         +35.6208\n",
      "        33     -342792.1598          +8.9111\n",
      "        34     -342786.3426          +5.8172\n",
      "        35     -342779.8812          +6.4614\n",
      "        36     -342771.4717          +8.4095\n",
      "        37     -342760.4114         +11.0603\n",
      "        38     -342746.9271         +13.4844\n",
      "        39     -342735.0529         +11.8742\n",
      "        40     -342726.0853          +8.9676\n",
      "        41     -342718.6472          +7.4381\n",
      "        42     -342711.5095          +7.1377\n",
      "        43     -342703.8173          +7.6922\n",
      "        44     -342695.4653          +8.3520\n",
      "        45     -342689.0377          +6.4276\n",
      "        46     -342683.8783          +5.1594\n",
      "        47     -342679.5263          +4.3520\n",
      "        48     -342675.9567          +3.5696\n",
      "        49     -342673.1331          +2.8236\n",
      "        50     -342670.9455          +2.1876\n",
      "        51     -342669.2263          +1.7192\n",
      "        52     -342667.7843          +1.4420\n",
      "        53     -342666.4077          +1.3766\n",
      "        54     -342664.8980          +1.5097\n",
      "        55     -342663.2074          +1.6906\n",
      "        56     -342661.5712          +1.6362\n",
      "        57     -342660.5044          +1.0668\n",
      "        58     -342659.9078          +0.5966\n",
      "        59     -342659.5414          +0.3664\n",
      "        60     -342659.2976          +0.2438\n",
      "        61     -342659.1165          +0.1811\n",
      "        62     -342658.9509          +0.1656\n",
      "        63     -342658.7309          +0.2201\n",
      "        64     -342658.2487          +0.4822\n",
      "        65     -342657.0200          +1.2286\n",
      "        66     -342655.5671          +1.4530\n",
      "        67     -342654.0950          +1.4720\n",
      "        68     -342651.5735          +2.5215\n",
      "        69     -342649.1069          +2.4667\n",
      "        70     -342647.7448          +1.3620\n",
      "        71     -342646.9767          +0.7681\n",
      "        72     -342645.5175          +1.4593\n",
      "        73     -342643.3445          +2.1729\n",
      "        74     -342642.4982          +0.8464\n",
      "        75     -342641.5422          +0.9560\n",
      "        76     -342640.6009          +0.9412\n",
      "        77     -342640.1080          +0.4929\n",
      "        78     -342639.7773          +0.3307\n",
      "        79     -342639.3590          +0.4183\n",
      "        80     -342638.4439          +0.9151\n",
      "        81     -342637.3893          +1.0546\n",
      "        82     -342636.8526          +0.5366\n",
      "        83     -342636.2891          +0.5635\n",
      "        84     -342635.1150          +1.1741\n",
      "        85     -342632.1534          +2.9616\n",
      "        86     -342627.6725          +4.4809\n",
      "        87     -342622.0397          +5.6328\n",
      "        88     -342618.0785          +3.9612\n",
      "        89     -342615.2355          +2.8430\n",
      "        90     -342613.1917          +2.0438\n",
      "        91     -342611.5422          +1.6495\n",
      "        92     -342609.9190          +1.6232\n",
      "        93     -342608.1439          +1.7752\n",
      "        94     -342606.4738          +1.6701\n",
      "        95     -342605.1032          +1.3706\n",
      "        96     -342603.9110          +1.1922\n",
      "        97     -342602.6419          +1.2691\n",
      "        98     -342600.5747          +2.0673\n",
      "        99     -342597.2665          +3.3081\n",
      "       100     -342594.3687          +2.8979\n",
      "       101     -342589.9708          +4.3979\n",
      "       102     -342586.2962          +3.6746\n",
      "       103     -342584.5122          +1.7840\n",
      "       104     -342583.7117          +0.8005\n",
      "       105     -342583.3096          +0.4021\n",
      "       106     -342583.0872          +0.2224\n",
      "       107     -342582.9615          +0.1257\n",
      "       108     -342582.8903          +0.0712\n",
      "       109     -342582.8493          +0.0411\n",
      "       110     -342582.8238          +0.0254\n",
      "       111     -342582.7975          +0.0263\n",
      "       112     -342582.6836          +0.1140\n",
      "       113     -342582.0464          +0.6371\n",
      "       114     -342580.8889          +1.1576\n",
      "       115     -342580.1006          +0.7883\n",
      "       116     -342578.1565          +1.9440\n",
      "       117     -342576.8055          +1.3511\n",
      "       118     -342576.6568          +0.1487\n",
      "       119     -342576.5802          +0.0766\n",
      "       120     -342576.5295          +0.0506\n",
      "       121     -342576.4928          +0.0368\n",
      "       122     -342576.4643          +0.0285\n",
      "       123     -342576.4411          +0.0232\n",
      "       124     -342576.4217          +0.0194\n",
      "       125     -342576.4053          +0.0164\n",
      "       126     -342576.3913          +0.0140\n",
      "       127     -342576.3795          +0.0118\n",
      "       128     -342576.3696          +0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class gia_dinh\n",
      "(3826, 36) [51, 46, 55, 43, 35, 66, 41, 76, 47, 40, 46, 71, 45, 51, 40, 51, 41, 41, 53, 47, 61, 37, 51, 51, 51, 47, 36, 44, 43, 46, 46, 43, 39, 49, 44, 46, 51, 53, 37, 49, 33, 51, 51, 37, 46, 41, 66, 39, 37, 49, 45, 47, 31, 41, 41, 46, 45, 71, 43, 66, 51, 56, 49, 51, 71, 33, 55, 35, 49, 41, 41, 51, 51, 61, 45, 43, 61, 41, 66, 39] 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -405814.4448             +nan\n",
      "         2     -387155.4716      +18658.9732\n",
      "         3     -383223.0495       +3932.4221\n",
      "         4     -381879.9907       +1343.0588\n",
      "         5     -381086.1360        +793.8547\n",
      "         6     -380397.5614        +688.5746\n",
      "         7     -379875.7562        +521.8052\n",
      "         8     -379540.9736        +334.7826\n",
      "         9     -379270.4803        +270.4933\n",
      "        10     -379119.1668        +151.3136\n",
      "        11     -379030.2656         +88.9012\n",
      "        12     -378976.4024         +53.8632\n",
      "        13     -378930.2201         +46.1823\n",
      "        14     -378872.6642         +57.5560\n",
      "        15     -378848.8583         +23.8059\n",
      "        16     -378831.1378         +17.7205\n",
      "        17     -378810.2955         +20.8424\n",
      "        18     -378799.7290         +10.5665\n",
      "        19     -378793.4167          +6.3122\n",
      "        20     -378788.2406          +5.1761\n",
      "        21     -378783.0360          +5.2046\n",
      "        22     -378776.9545          +6.0815\n",
      "        23     -378770.5154          +6.4392\n",
      "        24     -378764.0409          +6.4745\n",
      "        25     -378757.1261          +6.9148\n",
      "        26     -378746.3166         +10.8095\n",
      "        27     -378725.5542         +20.7624\n",
      "        28     -378699.9629         +25.5914\n",
      "        29     -378680.3091         +19.6538\n",
      "        30     -378660.8688         +19.4402\n",
      "        31     -378636.7245         +24.1443\n",
      "        32     -378596.0935         +40.6310\n",
      "        33     -378526.3729         +69.7206\n",
      "        34     -378431.1269         +95.2460\n",
      "        35     -378355.4402         +75.6866\n",
      "        36     -378337.4835         +17.9567\n",
      "        37     -378334.2921          +3.1914\n",
      "        38     -378332.5142          +1.7779\n",
      "        39     -378330.5705          +1.9436\n",
      "        40     -378325.2543          +5.3163\n",
      "        41     -378318.0173          +7.2370\n",
      "        42     -378314.4621          +3.5551\n",
      "        43     -378310.7555          +3.7067\n",
      "        44     -378303.3736          +7.3818\n",
      "        45     -378297.3474          +6.0263\n",
      "        46     -378295.2068          +2.1406\n",
      "        47     -378289.8197          +5.3870\n",
      "        48     -378272.6795         +17.1402\n",
      "        49     -378270.2231          +2.4564\n",
      "        50     -378268.6962          +1.5269\n",
      "        51     -378267.7785          +0.9178\n",
      "        52     -378267.2459          +0.5325\n",
      "        53     -378266.8846          +0.3613\n",
      "        54     -378266.4836          +0.4011\n",
      "        55     -378265.6846          +0.7990\n",
      "        56     -378264.4424          +1.2422\n",
      "        57     -378263.1100          +1.3324\n",
      "        58     -378260.1478          +2.9622\n",
      "        59     -378258.2573          +1.8905\n",
      "        60     -378257.5994          +0.6580\n",
      "        61     -378257.2139          +0.3855\n",
      "        62     -378256.9404          +0.2735\n",
      "        63     -378256.7319          +0.2085\n",
      "        64     -378256.5743          +0.1576\n",
      "        65     -378256.4622          +0.1121\n",
      "        66     -378256.3891          +0.0730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        67     -378256.3455          +0.0436\n",
      "        68     -378256.3212          +0.0243\n",
      "        69     -378256.3083          +0.0129\n",
      "        70     -378256.3016          +0.0067\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "for cname in class_names:\n",
    "    # convert all vectors to the cluster index\n",
    "    # dataset['one'] = [O^1, ... O^R]\n",
    "    # O^r = (c1, c2, ... ct, ... cT)\n",
    "    # O^r size T x 1\n",
    "    hmm = hmmlearn.hmm.GMMHMM(\n",
    "        n_components=6, n_mix = 2, random_state=42, n_iter=1000, verbose=True,\n",
    "        params='mctw',\n",
    "        init_params='m',\n",
    "#         startprob_prior = np.array([1.0,0.0,0.0,0.0,0.0]),\n",
    "#         transmat_prior = np.array([\n",
    "#             [0.7,0.3,0.0,0.0,0.0],\n",
    "#             [0.0,0.7,0.3,0.0,0.0],\n",
    "#             [0.0,0.0,0.7,0.3,0.0],\n",
    "#             [0.0,0.0,0.0,0.7,0.3],\n",
    "#             [0.0,0.0,0.0,0.0,1.0],\n",
    "#         ])\n",
    "    )\n",
    "    hmm.startprob_ = np.array([1.0,0.0,0.0,0.0,0.0, 0.0])\n",
    "#     hmm.transmat_ = np.array([\n",
    "#             [0.7,0.3,0.0,0.0,0.0],\n",
    "#             [0.0,0.7,0.3,0.0,0.0],\n",
    "#             [0.0,0.0,0.7,0.3,0.0],\n",
    "#             [0.0,0.0,0.0,0.7,0.3],\n",
    "#             [0.0,0.0,0.0,0.0,1.0],\n",
    "#         ])\n",
    "\n",
    "    if cname[:4] != 'test':\n",
    "        X = np.concatenate(dataset[cname])\n",
    "        lengths = list([len(x) for x in dataset[cname]])\n",
    "        print(\"training class\", cname)\n",
    "        print(X.shape, lengths, len(lengths))\n",
    "        hmm.fit(X)\n",
    "        models[cname] = hmm\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "test_gia_dinh {'toi': -7049.10545635477, 'trong': -7314.762307790923, 'truoc': -7392.4952671252195, 'nhan_vien': -7187.929821430053, 'gia_dinh': -6765.3010811142485} gia_dinh\n",
      "test_gia_dinh {'toi': -4166.4293495251, 'trong': -4359.920307921832, 'truoc': -4453.194743684829, 'nhan_vien': -4375.023125680764, 'gia_dinh': -4006.244066802912} gia_dinh\n",
      "test_gia_dinh {'toi': -4569.877055652338, 'trong': -4664.928658034754, 'truoc': -4763.140738238798, 'nhan_vien': -4561.867350291636, 'gia_dinh': -4255.766475877744} gia_dinh\n",
      "test_gia_dinh {'toi': -4661.549532072559, 'trong': -4743.795751137741, 'truoc': -4923.571048487526, 'nhan_vien': -4661.287952729645, 'gia_dinh': -4409.028947340244} gia_dinh\n",
      "test_gia_dinh {'toi': -4851.871170114552, 'trong': -5030.575470702249, 'truoc': -5078.20675841581, 'nhan_vien': -4925.33342200247, 'gia_dinh': -4562.481772355831} gia_dinh\n",
      "test_gia_dinh {'toi': -6465.859671994828, 'trong': -6853.169574531901, 'truoc': -6933.533784424791, 'nhan_vien': -6673.061471450126, 'gia_dinh': -6097.857624423319} gia_dinh\n",
      "test_gia_dinh {'toi': -6182.939128213712, 'trong': -6377.450629384806, 'truoc': -6609.05004905157, 'nhan_vien': -6259.328260495557, 'gia_dinh': -5675.579874599432} gia_dinh\n",
      "test_gia_dinh {'toi': -4483.500343035158, 'trong': -4601.416917252914, 'truoc': -4746.840605064713, 'nhan_vien': -4566.910542162904, 'gia_dinh': -4063.6317917934052} gia_dinh\n",
      "test_gia_dinh {'toi': -5879.920041697538, 'trong': -6146.853636917008, 'truoc': -6220.5166841033115, 'nhan_vien': -5880.290537157346, 'gia_dinh': -5525.1795659826375} gia_dinh\n",
      "test_gia_dinh {'toi': -8140.021564147571, 'trong': -8516.329633641803, 'truoc': -8916.05438028547, 'nhan_vien': -8729.494059821636, 'gia_dinh': -8033.855505733615} gia_dinh\n",
      "test_gia_dinh {'toi': -4709.377200451466, 'trong': -4840.12949272219, 'truoc': -4901.078441622946, 'nhan_vien': -4720.925669122524, 'gia_dinh': -4515.059693039764} gia_dinh\n",
      "test_gia_dinh {'toi': -4522.657151156756, 'trong': -4653.103610753183, 'truoc': -4767.49737614985, 'nhan_vien': -4551.495165725511, 'gia_dinh': -4223.379451446857} gia_dinh\n",
      "test_gia_dinh {'toi': -3658.1378072092975, 'trong': -3823.2069418456636, 'truoc': -3937.7663506845756, 'nhan_vien': -3804.927756933356, 'gia_dinh': -3511.9868576006156} gia_dinh\n",
      "test_gia_dinh {'toi': -4915.831739695451, 'trong': -5114.990516218565, 'truoc': -5208.448898851173, 'nhan_vien': -5012.406828141378, 'gia_dinh': -4635.222202218336} gia_dinh\n",
      "test_gia_dinh {'toi': -4390.260308231233, 'trong': -4466.736573321202, 'truoc': -4548.441809312479, 'nhan_vien': -4452.409964938974, 'gia_dinh': -4158.524342834272} gia_dinh\n",
      "test_gia_dinh {'toi': -4747.702509866774, 'trong': -4847.185867228529, 'truoc': -4988.580517056578, 'nhan_vien': -4760.093649796283, 'gia_dinh': -4438.666434082751} gia_dinh\n",
      "test_gia_dinh {'toi': -6063.1690311486345, 'trong': -6277.508590803328, 'truoc': -6455.92784433334, 'nhan_vien': -6094.575985613947, 'gia_dinh': -5793.632952484917} gia_dinh\n",
      "test_gia_dinh {'toi': -5583.444324230039, 'trong': -5704.33333744479, 'truoc': -5846.70023674242, 'nhan_vien': -5608.299868643958, 'gia_dinh': -5266.92133576905} gia_dinh\n",
      "test_gia_dinh {'toi': -4854.971902478057, 'trong': -4990.4048050771335, 'truoc': -5022.530055714187, 'nhan_vien': -4812.251485668298, 'gia_dinh': -4605.975946362635} gia_dinh\n",
      "test_gia_dinh {'toi': -4358.580363548203, 'trong': -4322.171920704669, 'truoc': -4553.670622041749, 'nhan_vien': -4423.745163184187, 'gia_dinh': -3970.610061131958} gia_dinh\n",
      "test_nhan_vien {'toi': -4775.364333636509, 'trong': -4999.160491011806, 'truoc': -4966.530179975353, 'nhan_vien': -4654.898945853802, 'gia_dinh': -4797.06851432275} nhan_vien\n",
      "test_nhan_vien {'toi': -5289.109265402426, 'trong': -5608.756843244107, 'truoc': -5387.637279057204, 'nhan_vien': -5075.009378527442, 'gia_dinh': -5065.055550410644} gia_dinh\n",
      "test_nhan_vien {'toi': -3729.454863043374, 'trong': -3775.422678117151, 'truoc': -3842.0556689179966, 'nhan_vien': -3588.698786082941, 'gia_dinh': -3662.115034199675} nhan_vien\n",
      "test_nhan_vien {'toi': -4377.024379835882, 'trong': -4373.131576177383, 'truoc': -4437.318609952447, 'nhan_vien': -4232.437713177142, 'gia_dinh': -4367.883296596321} nhan_vien\n",
      "test_nhan_vien {'toi': -4426.787726336812, 'trong': -4516.257479189117, 'truoc': -4588.079952920613, 'nhan_vien': -4217.308589102648, 'gia_dinh': -4203.4186482237} gia_dinh\n",
      "test_nhan_vien {'toi': -4936.017446689042, 'trong': -5134.933778001111, 'truoc': -4935.210647065989, 'nhan_vien': -4601.924378272265, 'gia_dinh': -4743.660674166124} nhan_vien\n",
      "test_nhan_vien {'toi': -4999.636283734291, 'trong': -5134.04704211188, 'truoc': -5081.180519740404, 'nhan_vien': -4695.69731783262, 'gia_dinh': -4824.6142104378205} nhan_vien\n",
      "test_nhan_vien {'toi': -4354.9911720484015, 'trong': -4436.325838936062, 'truoc': -4466.017138630607, 'nhan_vien': -4165.485514318839, 'gia_dinh': -4367.281388720502} nhan_vien\n",
      "test_nhan_vien {'toi': -3333.025237526585, 'trong': -3436.7703937688398, 'truoc': -3435.4310299008403, 'nhan_vien': -3169.1112787040374, 'gia_dinh': -3314.9163536343412} nhan_vien\n",
      "test_nhan_vien {'toi': -3388.08077075639, 'trong': -3487.7477360081552, 'truoc': -3480.1903612367187, 'nhan_vien': -3237.126927772206, 'gia_dinh': -3355.076591935973} nhan_vien\n",
      "test_nhan_vien {'toi': -3830.137629571148, 'trong': -3887.756376658196, 'truoc': -3944.986376129662, 'nhan_vien': -3669.824673388625, 'gia_dinh': -3818.993549755634} nhan_vien\n",
      "test_nhan_vien {'toi': -4925.082650646558, 'trong': -5100.919481258797, 'truoc': -4861.855413972536, 'nhan_vien': -4676.049164845609, 'gia_dinh': -4852.195230159294} nhan_vien\n",
      "test_nhan_vien {'toi': -5650.555096479151, 'trong': -5810.577418389477, 'truoc': -5695.981243116773, 'nhan_vien': -5431.035826130801, 'gia_dinh': -5538.409194662434} nhan_vien\n",
      "test_nhan_vien {'toi': -3376.7592103756533, 'trong': -3493.036480935741, 'truoc': -3487.8452449769047, 'nhan_vien': -3196.593499887733, 'gia_dinh': -3305.020951266408} nhan_vien\n",
      "test_nhan_vien {'toi': -4545.543505400416, 'trong': -4716.572446663561, 'truoc': -4767.167175437456, 'nhan_vien': -4353.670401539379, 'gia_dinh': -4488.954690633245} nhan_vien\n",
      "test_nhan_vien {'toi': -3463.643404130642, 'trong': -3625.132090745876, 'truoc': -3642.144248319272, 'nhan_vien': -3454.7112280632987, 'gia_dinh': -3430.3323116970123} gia_dinh\n",
      "test_nhan_vien {'toi': -3982.55656161462, 'trong': -4133.614687088142, 'truoc': -4139.989329491235, 'nhan_vien': -3683.8101046938405, 'gia_dinh': -3858.875439168637} nhan_vien\n",
      "test_nhan_vien {'toi': -4020.7964565181996, 'trong': -4140.940248401905, 'truoc': -4154.938015891933, 'nhan_vien': -3974.0017605543158, 'gia_dinh': -3915.145372256554} gia_dinh\n",
      "test_nhan_vien {'toi': -4677.273408493783, 'trong': -4799.263160938481, 'truoc': -4854.848099414557, 'nhan_vien': -4490.091882067038, 'gia_dinh': -4646.061367176027} nhan_vien\n",
      "test_nhan_vien {'toi': -3845.2330558282256, 'trong': -4023.498631593916, 'truoc': -4005.3888902148738, 'nhan_vien': -3764.6427675840814, 'gia_dinh': -3865.3868272401737} nhan_vien\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'test_song'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ab13905b3175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrue_cname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mkt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mO\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_cname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcname\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'test'\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0minverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'test_song'"
     ]
    }
   ],
   "source": [
    "print(\"Testing\")\n",
    "miss = {}\n",
    "test_name = { \"test_toi\", \"test_song\", \"test_truoc\", \"test_nhan_vien\", \"test_gia_dinh\"}\n",
    "for true_cname in test_name:\n",
    "    kt = 0\n",
    "    for O in dataset[true_cname]:\n",
    "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
    "        inverse = [(value, key) for key, value in score.items()]\n",
    "        pre = max(inverse)[1]\n",
    "        print(true_cname, score, pre)\n",
    "        if pre != true_cname[5:]:\n",
    "            kt +=1\n",
    "    miss[true_cname] = kt\n",
    "print(miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing\")\n",
    "miss = {}\n",
    "class_names = [\"toi\", \"song\", \"truoc\", \"nhan_vien\", \"gia_dinh\"]\n",
    "for true_cname in class_names:\n",
    "    kt = 0\n",
    "    for O in dataset[true_cname]:\n",
    "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
    "        inverse = [(value, key) for key, value in score.items()]\n",
    "        pre = max(inverse)[1]\n",
    "        print(true_cname, score, pre)\n",
    "        if pre != true_cname:\n",
    "            kt +=1\n",
    "    miss[true_cname] = kt\n",
    "print(miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "# with open(\"output.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
