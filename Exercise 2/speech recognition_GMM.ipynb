{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path) # read .wav file\n",
    "    hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "    win_length = math.floor(sr*0.025) # 25ms frame\n",
    "    # mfcc is 12 x T matrix\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y, sr, n_mfcc=12, n_fft=1024,\n",
    "        hop_length=hop_length, win_length=win_length)\n",
    "    # substract mean from mfcc --> normalize mfcc\n",
    "    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "    # delta feature 1st order and 2nd order\n",
    "    delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    # X is 36 x T\n",
    "    X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "    # return T x 36 (transpose of X)\n",
    "    return X.T # hmmlearn use T x N matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_data(data_dir):\n",
    "    files = os.listdir(data_dir)\n",
    "#     for f in files:\n",
    "#         print(f)\n",
    "    mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(X, n_clusters=10):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0, verbose=0)\n",
    "    kmeans.fit(X)\n",
    "    print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "    return kmeans  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load toi dataset\n",
      "Load song dataset\n",
      "Load truoc dataset\n",
      "Load nhan_vien dataset\n",
      "Load gia_dinh dataset\n",
      "Load test_toi dataset\n",
      "Load test_song dataset\n",
      "Load test_truoc dataset\n",
      "Load test_nhan_vien dataset\n",
      "Load test_gia_dinh dataset\n",
      "vectors (21611, 36)\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"toi\", \"song\", \"truoc\", \"nhan_vien\", \"gia_dinh\", \"test_toi\", \"test_song\", \"test_truoc\", \n",
    "               \"test_nhan_vien\", \"test_gia_dinh\"]\n",
    "dataset = {}\n",
    "for cname in class_names:\n",
    "    print(f\"Load {cname} dataset\")\n",
    "    dataset[cname] = get_class_data(os.path.join(\"data\", cname))\n",
    "\n",
    "# Get all vectors in the datasets\n",
    "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
    "print(\"vectors\", all_vectors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class toi\n",
      "(3490, 36) [22, 389, 36, 126, 28, 39, 98, 33, 23, 27, 21, 20, 23, 40, 36, 18, 25, 12, 22, 19, 14, 34, 22, 30, 47, 22, 29, 21, 17, 19, 31, 105, 24, 27, 19, 38, 25, 21, 84, 24, 22, 17, 17, 16, 142, 21, 36, 17, 18, 20, 18, 18, 32, 33, 29, 18, 47, 17, 19, 20, 18, 17, 49, 14, 31, 25, 18, 30, 24, 82, 26, 17, 16, 15, 24, 31, 16, 169, 20, 20, 149, 13, 123, 22, 34, 23, 131, 22, 24] 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -340834.8327             +nan\n",
      "         2     -318767.2881      +22067.5446\n",
      "         3     -312092.3800       +6674.9081\n",
      "         4     -310707.7561       +1384.6239\n",
      "         5     -310304.7026        +403.0534\n",
      "         6     -310121.1784        +183.5242\n",
      "         7     -309988.7226        +132.4558\n",
      "         8     -309918.3428         +70.3798\n",
      "         9     -309874.5546         +43.7881\n",
      "        10     -309838.6723         +35.8824\n",
      "        11     -309784.7330         +53.9393\n",
      "        12     -309709.1466         +75.5863\n",
      "        13     -309619.3101         +89.8366\n",
      "        14     -309456.2406        +163.0695\n",
      "        15     -309325.9262        +130.3144\n",
      "        16     -309256.0845         +69.8416\n",
      "        17     -309215.9093         +40.1753\n",
      "        18     -309174.5024         +41.4069\n",
      "        19     -309157.2758         +17.2266\n",
      "        20     -309142.8918         +14.3840\n",
      "        21     -309126.9358         +15.9560\n",
      "        22     -309112.2342         +14.7015\n",
      "        23     -309095.1159         +17.1184\n",
      "        24     -309084.6907         +10.4252\n",
      "        25     -309074.4962         +10.1945\n",
      "        26     -309065.2202          +9.2760\n",
      "        27     -309059.1678          +6.0524\n",
      "        28     -309054.7683          +4.3994\n",
      "        29     -309051.0621          +3.7062\n",
      "        30     -309047.7072          +3.3549\n",
      "        31     -309044.4489          +3.2583\n",
      "        32     -309040.4772          +3.9717\n",
      "        33     -309034.6345          +5.8427\n",
      "        34     -309024.9758          +9.6587\n",
      "        35     -309003.5536         +21.4222\n",
      "        36     -308975.2961         +28.2575\n",
      "        37     -308961.2341         +14.0620\n",
      "        38     -308959.0174          +2.2167\n",
      "        39     -308958.6637          +0.3537\n",
      "        40     -308958.0155          +0.6482\n",
      "        41     -308954.9200          +3.0955\n",
      "        42     -308954.4135          +0.5065\n",
      "        43     -308954.3825          +0.0311\n",
      "        44     -308954.3661          +0.0163\n",
      "        45     -308954.3554          +0.0107\n",
      "        46     -308954.3475          +0.0079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class song\n",
      "(4580, 36) [25, 32, 47, 31, 24, 35, 54, 27, 35, 51, 34, 24, 25, 93, 188, 158, 17, 187, 46, 26, 31, 35, 30, 32, 28, 25, 31, 45, 30, 26, 43, 45, 168, 206, 33, 31, 35, 41, 43, 33, 46, 32, 82, 30, 47, 32, 47, 47, 42, 47, 41, 42, 33, 47, 36, 31, 122, 24, 36, 162, 30, 33, 34, 32, 27, 76, 44, 45, 30, 35, 31, 152, 43, 31, 163, 54, 30, 45, 26, 25, 44, 24, 17, 42, 26, 33, 42, 32, 31, 33, 43, 51] 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -452980.9075             +nan\n",
      "         2     -414897.8669      +38083.0407\n",
      "         3     -407005.5797       +7892.2872\n",
      "         4     -405287.8519       +1717.7277\n",
      "         5     -404517.5334        +770.3186\n",
      "         6     -404148.5407        +368.9927\n",
      "         7     -403983.7523        +164.7884\n",
      "         8     -403808.2416        +175.5106\n",
      "         9     -403692.0035        +116.2382\n",
      "        10     -403633.2687         +58.7347\n",
      "        11     -403593.2964         +39.9724\n",
      "        12     -403553.9078         +39.3886\n",
      "        13     -403516.4992         +37.4086\n",
      "        14     -403487.3322         +29.1669\n",
      "        15     -403465.7157         +21.6165\n",
      "        16     -403448.8027         +16.9131\n",
      "        17     -403436.2811         +12.5215\n",
      "        18     -403412.9258         +23.3554\n",
      "        19     -403367.0454         +45.8804\n",
      "        20     -403320.8928         +46.1526\n",
      "        21     -403290.2918         +30.6010\n",
      "        22     -403271.2889         +19.0030\n",
      "        23     -403245.8578         +25.4311\n",
      "        24     -403204.0645         +41.7933\n",
      "        25     -403190.6125         +13.4520\n",
      "        26     -403176.7204         +13.8920\n",
      "        27     -403169.7182          +7.0022\n",
      "        28     -403160.5464          +9.1718\n",
      "        29     -403157.3424          +3.2039\n",
      "        30     -403155.7300          +1.6125\n",
      "        31     -403153.6333          +2.0967\n",
      "        32     -403150.3619          +3.2713\n",
      "        33     -403142.3015          +8.0604\n",
      "        34     -403133.8435          +8.4580\n",
      "        35     -403130.2262          +3.6173\n",
      "        36     -403127.3639          +2.8623\n",
      "        37     -403124.3612          +3.0027\n",
      "        38     -403121.7261          +2.6351\n",
      "        39     -403117.9752          +3.7510\n",
      "        40     -403110.6935          +7.2816\n",
      "        41     -403100.3908         +10.3027\n",
      "        42     -403099.0177          +1.3731\n",
      "        43     -403098.4830          +0.5348\n",
      "        44     -403098.0448          +0.4381\n",
      "        45     -403097.5791          +0.4658\n",
      "        46     -403096.5648          +1.0142\n",
      "        47     -403089.2362          +7.3286\n",
      "        48     -403077.4904         +11.7458\n",
      "        49     -403074.8945          +2.5958\n",
      "        50     -403069.6088          +5.2857\n",
      "        51     -403059.8589          +9.7499\n",
      "        52     -403056.1803          +3.6786\n",
      "        53     -403054.6395          +1.5408\n",
      "        54     -403053.8389          +0.8006\n",
      "        55     -403053.2484          +0.5905\n",
      "        56     -403052.6572          +0.5912\n",
      "        57     -403051.9381          +0.7191\n",
      "        58     -403051.1024          +0.8357\n",
      "        59     -403050.4118          +0.6906\n",
      "        60     -403049.9773          +0.4346\n",
      "        61     -403049.6450          +0.3322\n",
      "        62     -403049.2088          +0.4362\n",
      "        63     -403048.1639          +1.0449\n",
      "        64     -403041.3436          +6.8203\n",
      "        65     -403020.4829         +20.8607\n",
      "        66     -403012.4734          +8.0095\n",
      "        67     -402986.9220         +25.5515\n",
      "        68     -402975.5103         +11.4117\n",
      "        69     -402972.0566          +3.4537\n",
      "        70     -402969.1326          +2.9241\n",
      "        71     -402966.6844          +2.4481\n",
      "        72     -402965.2895          +1.3949\n",
      "        73     -402963.6196          +1.6700\n",
      "        74     -402923.6115         +40.0081\n",
      "        75     -402822.4871        +101.1244\n",
      "        76     -402818.5588          +3.9283\n",
      "        77     -402818.4642          +0.0946\n",
      "        78     -402818.4204          +0.0437\n",
      "        79     -402817.6249          +0.7955\n",
      "        80     -402813.9881          +3.6368\n",
      "        81     -402813.5022          +0.4859\n",
      "        82     -402813.4845          +0.0177\n",
      "        83     -402813.4792          +0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class truoc\n",
      "(2227, 36) [27, 20, 41, 31, 24, 26, 41, 21, 31, 26, 18, 23, 32, 23, 26, 21, 21, 37, 36, 26, 31, 15, 17, 19, 23, 41, 25, 31, 31, 26, 31, 26, 19, 35, 21, 22, 24, 20, 11, 31, 31, 22, 29, 33, 22, 29, 22, 23, 24, 31, 21, 31, 26, 25, 20, 27, 19, 28, 27, 36, 25, 35, 23, 31, 21, 41, 41, 36, 27, 61, 43, 43, 35, 36, 20, 19, 19, 46, 31, 18] 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -232141.9820             +nan\n",
      "         2     -217669.9872      +14471.9948\n",
      "         3     -215541.8457       +2128.1415\n",
      "         4     -215011.9735        +529.8721\n",
      "         5     -214776.3577        +235.6158\n",
      "         6     -214621.7716        +154.5861\n",
      "         7     -214518.0444        +103.7273\n",
      "         8     -214438.0290         +80.0154\n",
      "         9     -214365.6922         +72.3368\n",
      "        10     -214317.7074         +47.9848\n",
      "        11     -214284.2964         +33.4111\n",
      "        12     -214251.3497         +32.9466\n",
      "        13     -214215.0738         +36.2759\n",
      "        14     -214190.2176         +24.8562\n",
      "        15     -214175.0146         +15.2030\n",
      "        16     -214161.0916         +13.9230\n",
      "        17     -214145.2855         +15.8061\n",
      "        18     -214131.7128         +13.5728\n",
      "        19     -214117.9258         +13.7870\n",
      "        20     -214106.7252         +11.2006\n",
      "        21     -214094.3386         +12.3866\n",
      "        22     -214084.7893          +9.5493\n",
      "        23     -214078.4925          +6.2968\n",
      "        24     -214073.9441          +4.5484\n",
      "        25     -214068.6377          +5.3064\n",
      "        26     -214062.7801          +5.8576\n",
      "        27     -214059.2756          +3.5045\n",
      "        28     -214055.1043          +4.1712\n",
      "        29     -214039.2539         +15.8505\n",
      "        30     -214032.9038          +6.3501\n",
      "        31     -214019.0337         +13.8700\n",
      "        32     -214009.9386          +9.0951\n",
      "        33     -213999.9987          +9.9399\n",
      "        34     -213990.0254          +9.9734\n",
      "        35     -213982.4524          +7.5730\n",
      "        36     -213977.5977          +4.8547\n",
      "        37     -213973.7259          +3.8718\n",
      "        38     -213968.8792          +4.8467\n",
      "        39     -213964.3769          +4.5023\n",
      "        40     -213962.7458          +1.6311\n",
      "        41     -213962.0355          +0.7103\n",
      "        42     -213961.5834          +0.4520\n",
      "        43     -213961.2579          +0.3256\n",
      "        44     -213960.9913          +0.2666\n",
      "        45     -213960.7354          +0.2558\n",
      "        46     -213960.4985          +0.2369\n",
      "        47     -213960.3485          +0.1500\n",
      "        48     -213960.2785          +0.0700\n",
      "        49     -213960.2416          +0.0370\n",
      "        50     -213960.2181          +0.0235\n",
      "        51     -213960.2020          +0.0161\n",
      "        52     -213960.1906          +0.0114\n",
      "        53     -213960.1823          +0.0083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class nhan_vien\n",
      "(3622, 36) [50, 53, 65, 29, 33, 53, 50, 55, 47, 31, 44, 42, 36, 42, 46, 32, 40, 37, 55, 42, 39, 36, 29, 55, 43, 68, 33, 55, 55, 43, 53, 48, 55, 48, 53, 44, 34, 62, 40, 49, 35, 50, 41, 38, 44, 42, 53, 55, 30, 50, 78, 35, 52, 56, 40, 44, 50, 36, 34, 47, 63, 35, 65, 29, 36, 37, 34, 35, 63, 44, 45, 38, 40, 43, 47, 38, 39, 44, 38, 43, 32] 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -357113.2845             +nan\n",
      "         2     -344355.7306      +12757.5539\n",
      "         3     -340497.7097       +3858.0209\n",
      "         4     -339283.8129       +1213.8968\n",
      "         5     -338770.2195        +513.5934\n",
      "         6     -338561.6499        +208.5697\n",
      "         7     -338403.2590        +158.3908\n",
      "         8     -338274.0271        +129.2319\n",
      "         9     -338186.9896         +87.0375\n",
      "        10     -338130.0938         +56.8958\n",
      "        11     -338080.8417         +49.2521\n",
      "        12     -338037.5301         +43.3116\n",
      "        13     -338007.1065         +30.4236\n",
      "        14     -337982.2634         +24.8431\n",
      "        15     -337954.4470         +27.8164\n",
      "        16     -337917.6689         +36.7782\n",
      "        17     -337862.8539         +54.8150\n",
      "        18     -337833.3520         +29.5019\n",
      "        19     -337814.8777         +18.4743\n",
      "        20     -337797.6512         +17.2265\n",
      "        21     -337784.2154         +13.4358\n",
      "        22     -337768.7645         +15.4508\n",
      "        23     -337750.4878         +18.2767\n",
      "        24     -337726.2737         +24.2141\n",
      "        25     -337700.2180         +26.0557\n",
      "        26     -337678.0000         +22.2180\n",
      "        27     -337667.6964         +10.3036\n",
      "        28     -337661.6408          +6.0556\n",
      "        29     -337656.6293          +5.0115\n",
      "        30     -337651.8109          +4.8184\n",
      "        31     -337648.5945          +3.2164\n",
      "        32     -337646.2590          +2.3355\n",
      "        33     -337642.5936          +3.6654\n",
      "        34     -337633.6936          +8.9001\n",
      "        35     -337622.6045         +11.0890\n",
      "        36     -337614.0636          +8.5410\n",
      "        37     -337609.5943          +4.4693\n",
      "        38     -337606.8171          +2.7772\n",
      "        39     -337606.4402          +0.3768\n",
      "        40     -337606.2668          +0.1734\n",
      "        41     -337606.0955          +0.1713\n",
      "        42     -337605.7524          +0.3430\n",
      "        43     -337603.8203          +1.9322\n",
      "        44     -337599.8674          +3.9529\n",
      "        45     -337598.2937          +1.5736\n",
      "        46     -337597.6674          +0.6263\n",
      "        47     -337597.4331          +0.2343\n",
      "        48     -337597.3309          +0.1022\n",
      "        49     -337597.2798          +0.0511\n",
      "        50     -337597.2496          +0.0303\n",
      "        51     -337597.2283          +0.0212\n",
      "        52     -337597.2112          +0.0172\n",
      "        53     -337597.1955          +0.0157\n",
      "        54     -337597.1795          +0.0160\n",
      "        55     -337597.1614          +0.0181\n",
      "        56     -337597.1388          +0.0226\n",
      "        57     -337597.1084          +0.0304\n",
      "        58     -337597.0652          +0.0432\n",
      "        59     -337597.0037          +0.0615\n",
      "        60     -337596.9237          +0.0801\n",
      "        61     -337596.8388          +0.0849\n",
      "        62     -337596.7718          +0.0670\n",
      "        63     -337596.7319          +0.0399\n",
      "        64     -337596.7117          +0.0203\n",
      "        65     -337596.7017          +0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class gia_dinh\n",
      "(3826, 36) [51, 46, 55, 43, 35, 66, 41, 76, 47, 40, 46, 71, 45, 51, 40, 51, 41, 41, 53, 47, 61, 37, 51, 51, 51, 47, 36, 44, 43, 46, 46, 43, 39, 49, 44, 46, 51, 53, 37, 49, 33, 51, 51, 37, 46, 41, 66, 39, 37, 49, 45, 47, 31, 41, 41, 46, 45, 71, 43, 66, 51, 56, 49, 51, 71, 33, 55, 35, 49, 41, 41, 51, 51, 61, 45, 43, 61, 41, 66, 39] 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -404592.9311             +nan\n",
      "         2     -382758.9895      +21833.9416\n",
      "         3     -378482.3495       +4276.6400\n",
      "         4     -377143.1165       +1339.2330\n",
      "         5     -376416.8424        +726.2741\n",
      "         6     -376066.7585        +350.0838\n",
      "         7     -375864.1540        +202.6045\n",
      "         8     -375765.6344         +98.5197\n",
      "         9     -375738.9436         +26.6907\n",
      "        10     -375730.3438          +8.5998\n",
      "        11     -375724.3679          +5.9759\n",
      "        12     -375721.9445          +2.4234\n",
      "        13     -375719.5501          +2.3944\n",
      "        14     -375716.4462          +3.1039\n",
      "        15     -375714.1454          +2.3008\n",
      "        16     -375711.3659          +2.7796\n",
      "        17     -375706.5048          +4.8611\n",
      "        18     -375700.6679          +5.8368\n",
      "        19     -375695.2040          +5.4640\n",
      "        20     -375688.1472          +7.0568\n",
      "        21     -375679.6629          +8.4843\n",
      "        22     -375677.7284          +1.9345\n",
      "        23     -375677.3937          +0.3347\n",
      "        24     -375677.3260          +0.0678\n",
      "        25     -375677.2948          +0.0312\n",
      "        26     -375677.2783          +0.0165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        27     -375677.2691          +0.0092\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "for cname in class_names:\n",
    "    # convert all vectors to the cluster index\n",
    "    # dataset['one'] = [O^1, ... O^R]\n",
    "    # O^r = (c1, c2, ... ct, ... cT)\n",
    "    # O^r size T x 1\n",
    "    hmm = hmmlearn.hmm.GMMHMM(\n",
    "        n_components=7, n_mix = 2, random_state=42, n_iter=1000, verbose=True,\n",
    "        params='mctw',\n",
    "        init_params='mst',\n",
    "#         startprob_prior = np.array([1., 0., 0., 0., 0., 0., 0.]),\n",
    "#         transmat_prior = transitionMatrix()\n",
    "    )\n",
    "    hmm.startprob_ = np.array([1.0,0.0,0.0,0.0,0.0, 0.0,0.0])\n",
    "    hmm.transmat_ = np.array([\n",
    "            [0.7,0.3,0.0,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.7,0.3,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.7,0.3,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.7,0.3,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.0,0.7,0.3,0.0],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.7,0.3],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.0,1.0],\n",
    "        ])\n",
    "\n",
    "    if cname[:4] != 'test':\n",
    "        X = np.concatenate(dataset[cname])\n",
    "        lengths = list([len(x) for x in dataset[cname]])\n",
    "        print(\"training class\", cname)\n",
    "        print(X.shape, lengths, len(lengths))\n",
    "        hmm.fit(X)\n",
    "        models[cname] = hmm\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "test_gia_dinh   20\n",
      "test_nhan_vien   21\n",
      "test_song   20\n",
      "test_toi   20\n",
      "test_truoc   20\n",
      "{'test_gia_dinh': 100.0, 'test_nhan_vien': 100.0, 'test_song': 100.0, 'test_toi': 100.0, 'test_truoc': 100.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing\")\n",
    "acc = {}\n",
    "test_name = { \"test_toi\", \"test_song\", \"test_truoc\", \"test_nhan_vien\", \"test_gia_dinh\"}\n",
    "for true_cname in test_name:\n",
    "    kt = 0\n",
    "    for O in dataset[true_cname]:\n",
    "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
    "        inverse = [(value, key) for key, value in score.items()]\n",
    "        pre = max(inverse)[1]\n",
    "#         print(true_cname, score, pre)\n",
    "        if pre == true_cname[5:]:\n",
    "            kt +=1\n",
    "    print(true_cname,\" \", kt)\n",
    "    acc[true_cname] = kt * 100 / len(dataset[true_cname])\n",
    "print(acc)                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toi': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'song': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'truoc': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'nhan_vien': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'gia_dinh': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]]))}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "toi   89\n",
      "song   92\n",
      "truoc   80\n",
      "nhan_vien   81\n",
      "gia_dinh   79\n",
      "{'toi': 100.0, 'song': 100.0, 'truoc': 100.0, 'nhan_vien': 100.0, 'gia_dinh': 98.75}\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing\")\n",
    "miss = {}\n",
    "acc = {}\n",
    "class_names = [\"toi\", \"song\", \"truoc\", \"nhan_vien\", \"gia_dinh\"]\n",
    "for true_cname in class_names:\n",
    "    kt = 0\n",
    "    for O in dataset[true_cname]:\n",
    "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
    "        inverse = [(value, key) for key, value in score.items()]\n",
    "        pre = max(inverse)[1]\n",
    "#         print(true_cname, score, pre)\n",
    "        if pre == true_cname:\n",
    "            kt +=1\n",
    "    print(true_cname,\" \", kt)\n",
    "    acc[true_cname] = kt * 100 / len(dataset[true_cname])\n",
    "print(acc)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open(\"output1.pkl\", \"wb\") as file:\n",
    "    pickle.dump(models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentiendat/anaconda3/lib/python3.7/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gia_dinh'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O = get_mfcc('data.wav')\n",
    "score = {cname: model.score(O, [len(O)]) for cname, model in models.items()}\n",
    "inverse = [(value, key) for key, value in score.items()]\n",
    "predict = max(inverse)[1]\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load test_toi dataset\n",
      "vectors (895, 36)\n",
      "Testing\n",
      "test_toi {'toi': -7620.212225111643, 'song': -8230.521415545485, 'truoc': -8144.95941912607, 'nhan_vien': -8055.198681860034, 'gia_dinh': -8394.809761647619} toi\n",
      "test_toi {'toi': -2149.219995999329, 'song': -2412.9368211004685, 'truoc': -2362.355993332991, 'nhan_vien': -2303.6970214219964, 'gia_dinh': -2363.120670330845} toi\n",
      "test_toi {'toi': -4754.502610596342, 'song': -5116.315693293601, 'truoc': -5357.214125396858, 'nhan_vien': -5237.692756976712, 'gia_dinh': -4976.711196599017} toi\n",
      "test_toi {'toi': -1351.7292054794661, 'song': -1544.0518867550961, 'truoc': -1376.3849420262004, 'nhan_vien': -1426.545629349316, 'gia_dinh': -1475.5824434061235} toi\n",
      "test_toi {'toi': -2143.280006319747, 'song': -2328.4712382758908, 'truoc': -2223.3070208305335, 'nhan_vien': -2233.811970473114, 'gia_dinh': -2324.3715712918483} toi\n",
      "test_toi {'toi': -8820.564295791386, 'song': -9605.533709422523, 'truoc': -10004.417025004443, 'nhan_vien': -9616.831028032006, 'gia_dinh': -9375.206622770245} toi\n",
      "test_toi {'toi': -2069.5594524985504, 'song': -2242.3621953738175, 'truoc': -2212.2188260951916, 'nhan_vien': -2168.5605912476267, 'gia_dinh': -2280.2997491272645} toi\n",
      "test_toi {'toi': -1648.5222531713205, 'song': -1848.7494146082252, 'truoc': -1811.1386310755595, 'nhan_vien': -1775.2110488377677, 'gia_dinh': -1809.327739840239} toi\n",
      "test_toi {'toi': -11197.267099110528, 'song': -12506.81858905508, 'truoc': -12452.505117404919, 'nhan_vien': -12336.443860250385, 'gia_dinh': -12673.002387402235} toi\n",
      "test_toi {'toi': -3578.380490444765, 'song': -3687.392706508314, 'truoc': -3807.6792808771797, 'nhan_vien': -3604.1534383127887, 'gia_dinh': -3687.1969087526713} toi\n",
      "test_toi {'toi': -1660.1329564515217, 'song': -1787.282081670068, 'truoc': -1729.5932580958008, 'nhan_vien': -1725.2274217772508, 'gia_dinh': -1660.4557980246436} toi\n",
      "test_toi {'toi': -1965.4204392352544, 'song': -2192.2286103568154, 'truoc': -2180.344916623294, 'nhan_vien': -2150.5131991189965, 'gia_dinh': -2194.751003454861} toi\n",
      "test_toi {'toi': -2872.6013775332067, 'song': -3101.5967029959556, 'truoc': -3139.5279724399243, 'nhan_vien': -3084.2568805620344, 'gia_dinh': -3131.8406339020194} toi\n",
      "test_toi {'toi': -3141.133185969157, 'song': -3485.322137102206, 'truoc': -3425.9128291143825, 'nhan_vien': -3264.497107634756, 'gia_dinh': -3417.420818533449} toi\n",
      "test_toi {'toi': -5987.35172020553, 'song': -6470.820229200312, 'truoc': -6707.664235353807, 'nhan_vien': -6553.3051766719445, 'gia_dinh': -6549.155790545381} toi\n",
      "test_toi {'toi': -2179.252504098013, 'song': -2409.034512792424, 'truoc': -2477.363424350074, 'nhan_vien': -2407.8786648227974, 'gia_dinh': -2477.454439062274} toi\n",
      "test_toi {'toi': -5220.308773905552, 'song': -5610.727159225282, 'truoc': -5484.151265687306, 'nhan_vien': -5366.820821370678, 'gia_dinh': -5464.965975565016} toi\n",
      "test_toi {'toi': -2728.4369285261128, 'song': -2886.119989182102, 'truoc': -2875.944438472844, 'nhan_vien': -2876.0034908249545, 'gia_dinh': -3000.794752973401} toi\n",
      "test_toi {'toi': -6652.918530670467, 'song': -7194.208580314377, 'truoc': -7348.806686690741, 'nhan_vien': -7307.294100885237, 'gia_dinh': -7554.829966276977} toi\n",
      "test_toi {'toi': -3471.632892733901, 'song': -3770.7778292189487, 'truoc': -3681.4537269461403, 'nhan_vien': -3550.5078720265396, 'gia_dinh': -3517.094550167726} toi\n",
      "test_toi   20\n",
      "{'test_toi': 100.0}\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"test_toi\"]\n",
    "dataset = {}\n",
    "for cname in class_names:\n",
    "    print(f\"Load {cname} dataset\")\n",
    "    \n",
    "    dataset[cname] = get_class_data(os.path.join(\"data\", cname))\n",
    "\n",
    "# Get all vectors in the datasets\n",
    "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
    "print(\"vectors\", all_vectors.shape)\n",
    "\n",
    "print(\"Testing\")\n",
    "acc = {}\n",
    "test_name = { \"test_toi\"}\n",
    "for true_cname in test_name:\n",
    "    kt = 0\n",
    "    for O in dataset[true_cname]:\n",
    "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
    "        inverse = [(value, key) for key, value in score.items()]\n",
    "        pre = max(inverse)[1]\n",
    "        print(true_cname, score, pre)\n",
    "        if pre == true_cname[5:]:\n",
    "            kt +=1\n",
    "    print(true_cname,\" \", kt)\n",
    "    acc[true_cname] = kt * 100 / len(dataset[true_cname])\n",
    "print(acc)                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data\t     output1.pkl  'speech recognition_GMM.ipynb'   test.ipynb\r\n",
      " data.wav    output.pkl   'speech recognition.ipynb'\r\n",
      "'Get data'   song_1.wav    speech_recognition.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
